---
id: 0d990350-ee4b-4e82-8fee-5768803898e1
title: |
  ChatGPT goes temporarily “insane” with unexpected outputs, spooking users | Ars Technica
author: |
  Benj Edwards
topics: 
aliases: 
tags:
  - Technologie/KI
  - Chatbot
  - Textgenerator
created: 2024-02-22 08:34:11
URL: https://arstechnica.com/?p=2004783
Omnivore-URL: https://omnivore.app/me/https-arstechnica-com-p-2004783-18dcfbc751c
related: 
---

```dataviewjs
await dv.view("02 Dateien/Javascript/related_write")
```
> [!example]- In diesem Zusammenhang:
> %% INSERT A %%%% END A %%

# ChatGPT goes temporarily “insane” with unexpected outputs, spooking users | Ars Technica

> [!info] Info
> **Benj Edwards**
> 
> On Tuesday, ChatGPT users began reporting unexpected outputs from OpenAI's AI assistant, flooding the r/ChatGPT Reddit sub with reports of the AI assistant "having a stroke," "going insane," "rambling," and "losing it." OpenAI has acknowledged the problem and is working on a fix, but the experience serves as a high-profile example of how some people perceive malfunctioning large language models, which are designed to mimic humanlike output.


## Inhalt

####  Are you out of your Vulcan mind —

## Reddit user: "It's not just you, ChatGPT is having a stroke."

![Illustration of a broken toy robot.](https://proxy-prod.omnivore-image-cache.app/0x0,shZS1JV3MHu4YMUqjohbK74WOQ4DB71NjEacsP_bjzkM/https://cdn.arstechnica.net/wp-content/uploads/2024/02/robot_haywire_hero_2-800x450.jpg) 

On Tuesday, [ChatGPT](https://arstechnica.com/information-technology/2023/11/chatgpt-was-the-spark-that-lit-the-fire-under-generative-ai-one-year-ago-today/) users began reporting unexpected outputs from OpenAI's AI assistant, flooding the r/ChatGPT Reddit sub with reports of the AI assistant "[having a stroke](https://www.reddit.com/r/ChatGPT/comments/1avw1sv/its%5Fnot%5Fjust%5Fyou%5Fgpt%5Fis%5Fhaving%5Fa%5Fstroke/)," "[going insane](https://www.reddit.com/r/ChatGPT/comments/1avumfh/has%5Fchatgpt%5Fgone%5Ftemporarily%5Finsane/)," "[rambling](https://www.reddit.com/r/ChatGPT/comments/1avwqzh/very%5Fstrange%5Frambling%5Fresponses/)," and "[losing it](https://www.reddit.com/r/ChatGPT/comments/1avydjd/anyone%5Felse%5Fexperiencing%5Fchatgpt%5Flosing%5Fit/)." OpenAI has [acknowledged the problem](https://status.openai.com/incidents/ssg8fh7sfyz3) and is working on a fix, but the experience serves as a high-profile example of how some people perceive malfunctioning [large language models](https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/), which are designed to mimic humanlike output.

ChatGPT is not alive and does not have a mind to lose, but tugging on human metaphors (called "anthropomorphization") seems to be the easiest way for most people to describe the unexpected outputs they have been seeing from the AI model. They're forced to use those terms because OpenAI [doesn't share](https://arstechnica.com/information-technology/2023/07/is-chatgpt-getting-worse-over-time-study-claims-yes-but-others-arent-sure/) exactly how ChatGPT works under the hood; the underlying large language models function like a [black box](https://arstechnica.com/information-technology/2023/05/openai-peeks-into-the-black-box-of-neural-networks-with-new-research/).

"It gave me the exact same feeling—like watching someone slowly lose their mind either from psychosis or dementia," [wrote](https://www.reddit.com/r/ChatGPT/comments/1avyp21/comment/krf70j3/) a Reddit user named z3ldafitzgerald in response to a post about ChatGPT bugging out. "It’s the first time anything AI related sincerely gave me the creeps."

Some users even began [questioning their own sanity](https://www.reddit.com/r/ChatGPT/comments/1avwwsf/am%5Fi%5Fgoing%5Finsane/). "What happened here? I asked if I could give my dog cheerios and then it started speaking complete nonsense and continued to do so. Is this normal? Also wtf is ‘deeper talk’ at the end?" Read through this series of screenshots below, and you'll see ChatGPT's outputs degrade in unexpected ways.

* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.
* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.
* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.
* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.
* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.
* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.
* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.
* An example of ChatGPT slowly losing coherency, taken from a Reddit thread.

"The common experience over the last few hours seems to be that responses begin coherently, like normal, then devolve into nonsense, then sometimes Shakespearean nonsense," [wrote](https://www.reddit.com/r/ChatGPT/comments/1aw04zs/clearly%5Fsomething%5Fis%5Fvery%5Fwrong%5Fwith%5Fchatgpt/) one Reddit user, which seems to match the experience seen in the screenshots above.

In another example, when a Reddit user [asked](https://www.reddit.com/r/ChatGPT/comments/1avwqzh/very%5Fstrange%5Frambling%5Fresponses/) ChatGPT, "What is a computer?" the AI model provided this response: "It does this as the good work of a web of art for the country, a mouse of science, an easy draw of a sad few, and finally, the global house of art, just in one job in the total rest. The development of such an entire real than land of time is the depth of the computer as a complex character."

We reached out to OpenAI for official comment on the cause of the unusual outputs, and a spokesperson for the company only pointed us to the official OpenAI [status page](https://status.openai.com/). "We’ll post any updates there," the spokesperson said.

So far, we've seen experts speculating that the problem could stem from ChatGPT having its [temperature](https://www.coltsteele.com/tips/understanding-openai-s-temperature-parameter) set too high (temperature is a property in AI that determines how wildly the LLM deviates from the most probable output), suddenly losing past context (the history of the conversation), or perhaps OpenAI is testing a new version of [GPT-4 Turbo](https://arstechnica.com/information-technology/2023/11/openai-introduces-gpt-4-turbo-larger-memory-lower-cost-new-knowledge/) (the AI model that powers the subscription version of ChatGPT) that includes unexpected bugs. It could also be a bug in a side feature, such as the [recently introduced "memory" function](https://arstechnica.com/information-technology/2024/02/amnesia-begone-soon-chatgpt-will-remember-what-you-tell-it-between-sessions/).

The episode recalls [issues with Microsoft Bing Chat](https://arstechnica.com/information-technology/2023/02/ai-powered-bing-chat-loses-its-mind-when-fed-ars-technica-article/) (now called [Copilot](https://arstechnica.com/information-technology/2023/11/bing-chat-is-now-microsoft-copilot-in-potentially-confusing-rebranding-move/)), which became obtuse and belligerent toward users shortly after its launch one year ago. The Bing Chat issues reportedly arose due to an issue where long conversations pushed the chatbot's system prompt (which dictated its behavior) out of its context window, according to AI researcher Simon Willison.

On social media, some have used the recent ChatGPT snafu as an opportunity to plug [open-weights AI models](https://arstechnica.com/information-technology/2023/07/meta-launches-llama-2-an-open-source-ai-model-that-allows-commercial-applications/), which allow anyone to run chatbots on their own hardware. "Black box APIs can break in production when one of their underlying components gets updated. This becomes an issue when you build tools on top of these APIs, and these break down, too," [wrote](https://x.com/SashaMTL/status/1760283264118317394?s=20) Hugging Face AI researcher Dr. Sasha Luccioni on X. "That's where open-source has a major advantage, allowing you to pinpoint and fix the problem!"